{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "150805c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6059af27",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- **[Data](#1)**\n",
    "- **[Creating trainset](#2)**\n",
    "- **[Creating NN architechture](#3)**\n",
    "    - [ Embedding matrix](#3-1)\n",
    "    - [Understaning relations between train set and embedding matr](#3-2)\n",
    "    - [Evaluation](#3-3)\n",
    "    - [Improving forward pass and eval code](#3-4)\n",
    "    - [Backprob](#3-5)\n",
    "    - [Training in one loop](#3-6)\n",
    "    - [Model imporvement](#3-7)\n",
    "        - [Train, eval, test split](#3-6-1)\n",
    "        - [Increasing the model size](#3-6-2)\n",
    "        - [LR decay](#3-6-3)\n",
    "- **[Sampling](#4)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f97869",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b90cd1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f1b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "chars = ['.'] + chars\n",
    "\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d241a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '.',\n",
       " 1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4d9699",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "# Creating trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "cae09bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carely\n",
      "... ------> c\n",
      "..c ------> a\n",
      ".ca ------> r\n",
      "car ------> e\n",
      "are ------> l\n",
      "rel ------> y\n",
      "ely ------> .\n",
      "jullien\n",
      "... ------> j\n",
      "..j ------> u\n",
      ".ju ------> l\n",
      "jul ------> l\n",
      "ull ------> i\n",
      "lli ------> e\n",
      "lie ------> n\n",
      "ien ------> .\n",
      "sherly\n",
      "... ------> s\n",
      "..s ------> h\n",
      ".sh ------> e\n",
      "she ------> r\n",
      "her ------> l\n",
      "erl ------> y\n",
      "rly ------> .\n",
      "areeb\n",
      "... ------> a\n",
      "..a ------> r\n",
      ".ar ------> e\n",
      "are ------> e\n",
      "ree ------> b\n",
      "eeb ------> .\n",
      "harini\n",
      "... ------> h\n",
      "..h ------> a\n",
      ".ha ------> r\n",
      "har ------> i\n",
      "ari ------> n\n",
      "rin ------> i\n",
      "ini ------> .\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "BLOCK_SIZE = 3\n",
    "EMBEDDING_SIZE = 10 #2\n",
    "\n",
    "def build_dataset(words, block_size=BLOCK_SIZE, verbose=False):\n",
    "     # context length: how many charachters do we \n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "\n",
    "        if verbose: print(w)\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "\n",
    "            if verbose: print(''.join(itos[i] for i in context), '------>', itos[ix])\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    \n",
    "    return {'X': X, 'Y': Y}\n",
    "\n",
    "ds_dict = build_dataset(words=words[:5], verbose=True)\n",
    "X = ds_dict['X']\n",
    "Y = ds_dict['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4776bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 15],\n",
       "        [ 0, 15, 12],\n",
       "        [15, 12,  9],\n",
       "        [12,  9, 22],\n",
       "        [ 9, 22,  9],\n",
       "        [22,  9,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0,  1, 22],\n",
       "        [ 1, 22,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  9],\n",
       "        [ 0,  9, 19],\n",
       "        [ 9, 19,  1],\n",
       "        [19,  1,  2],\n",
       "        [ 1,  2,  5],\n",
       "        [ 2,  5, 12],\n",
       "        [ 5, 12, 12],\n",
       "        [12, 12,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 19],\n",
       "        [ 0, 19, 15],\n",
       "        [19, 15, 16],\n",
       "        [15, 16,  8],\n",
       "        [16,  8,  9],\n",
       "        [ 8,  9,  1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a476af11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1f688e",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "# Creating NN architechture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7857f586",
   "metadata": {},
   "source": [
    "<a name='3-1'></a>\n",
    "## Embedding matrix\n",
    "It follows the input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9a69c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((len(chars),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d89baf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAt the input stage we need to select the row of the embedding lookup matrix that is passed to the next layer. \\nFor this we can either simply select the needed layer like so C[5] or format the input as one-hot vectors\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "At the input stage we need to select the row of the embedding lookup matrix that is passed to the next layer. \n",
    "For this we can either simply select the needed layer like so C[5] or format the input as one-hot vectors\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7acb2b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_one_hot = F.one_hot(torch.tensor(2), num_classes=len(chars)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d511869e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_one_hot.unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a04125a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2994, 1.4347]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_one_hot.unsqueeze(dim=0) @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09bc3f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc0d2da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff9da8",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "## Understaning relations between train set and embedding matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4c28cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5696,  1.8836],\n",
       "        [-0.7986,  0.5644],\n",
       "        [ 0.2994,  1.4347],\n",
       "        [ 1.0980, -1.1331],\n",
       "        [-0.5800, -0.0969],\n",
       "        [ 1.6415,  1.8853],\n",
       "        [-0.7196,  1.6522],\n",
       "        [-0.7825, -0.5869],\n",
       "        [-1.2912,  0.2820],\n",
       "        [-1.2013,  0.2599],\n",
       "        [ 2.3951, -0.1519],\n",
       "        [-0.1747, -0.6222],\n",
       "        [-0.0168, -0.5608],\n",
       "        [-1.4189, -1.4393],\n",
       "        [-1.6985,  0.3681],\n",
       "        [ 1.8049, -1.0374],\n",
       "        [-0.3569,  0.6205],\n",
       "        [-0.0829, -0.3484],\n",
       "        [ 1.3456, -0.4632],\n",
       "        [ 0.3323,  1.4900],\n",
       "        [ 1.0436, -0.2684],\n",
       "        [ 1.5303, -0.1281],\n",
       "        [ 1.3819, -0.2589],\n",
       "        [ 0.1728, -0.2133],\n",
       "        [ 0.5602,  1.3424],\n",
       "        [-0.8026,  0.5389],\n",
       "        [ 1.6965,  1.9275]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C #all of the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "750d9814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[27, 2] # Original char -- 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4e05f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "804617de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.5696,  1.8836],\n",
       "         [-2.5696,  1.8836],\n",
       "         [-2.5696,  1.8836]],\n",
       "\n",
       "        [[-2.5696,  1.8836],\n",
       "         [-2.5696,  1.8836],\n",
       "         [ 1.6415,  1.8853]],\n",
       "\n",
       "        [[-2.5696,  1.8836],\n",
       "         [ 1.6415,  1.8853],\n",
       "         [-1.4189, -1.4393]],\n",
       "\n",
       "        [[ 1.6415,  1.8853],\n",
       "         [-1.4189, -1.4393],\n",
       "         [-1.4189, -1.4393]],\n",
       "\n",
       "        [[-1.4189, -1.4393],\n",
       "         [-1.4189, -1.4393],\n",
       "         [-0.7986,  0.5644]],\n",
       "\n",
       "        [[-2.5696,  1.8836],\n",
       "         [-2.5696,  1.8836],\n",
       "         [-2.5696,  1.8836]],\n",
       "\n",
       "        [[-2.5696,  1.8836],\n",
       "         [-2.5696,  1.8836],\n",
       "         [ 1.8049, -1.0374]],\n",
       "\n",
       "        [[-2.5696,  1.8836],\n",
       "         [ 1.8049, -1.0374],\n",
       "         [-0.0168, -0.5608]],\n",
       "\n",
       "        [[ 1.8049, -1.0374],\n",
       "         [-0.0168, -0.5608],\n",
       "         [-1.2013,  0.2599]],\n",
       "\n",
       "        [[-0.0168, -0.5608],\n",
       "         [-1.2013,  0.2599],\n",
       "         [ 1.3819, -0.2589]],\n",
       "\n",
       "        [[-1.2013,  0.2599],\n",
       "         [ 1.3819, -0.2589],\n",
       "         [-1.2013,  0.2599]],\n",
       "\n",
       "        [[ 1.3819, -0.2589],\n",
       "         [-1.2013,  0.2599],\n",
       "         [-0.7986,  0.5644]],\n",
       "\n",
       "        [[-2.5696,  1.8836],\n",
       "         [-2.5696,  1.8836],\n",
       "         [-2.5696,  1.8836]],\n",
       "\n",
       "        [[-2.5696,  1.8836],\n",
       "         [-2.5696,  1.8836],\n",
       "         [-0.7986,  0.5644]],\n",
       "\n",
       "        [[-2.5696,  1.8836],\n",
       "         [-0.7986,  0.5644],\n",
       "         [ 1.3819, -0.2589]],\n",
       "\n",
       "        [[-0.7986,  0.5644],\n",
       "         [ 1.3819, -0.2589],\n",
       "         [-0.7986,  0.5644]],\n",
       "\n",
       "        [[-2.5696,  1.8836],\n",
       "         [-2.5696,  1.8836],\n",
       "         [-2.5696,  1.8836]],\n",
       "\n",
       "        [[-2.5696,  1.8836],\n",
       "         [-2.5696,  1.8836],\n",
       "         [-1.2013,  0.2599]],\n",
       "\n",
       "        [[-2.5696,  1.8836],\n",
       "         [-1.2013,  0.2599],\n",
       "         [ 0.3323,  1.4900]],\n",
       "\n",
       "        [[-1.2013,  0.2599],\n",
       "         [ 0.3323,  1.4900],\n",
       "         [-0.7986,  0.5644]],\n",
       "\n",
       "        [[ 0.3323,  1.4900],\n",
       "         [-0.7986,  0.5644],\n",
       "         [ 0.2994,  1.4347]],\n",
       "\n",
       "        [[-0.7986,  0.5644],\n",
       "         [ 0.2994,  1.4347],\n",
       "         [ 1.6415,  1.8853]],\n",
       "\n",
       "        [[ 0.2994,  1.4347],\n",
       "         [ 1.6415,  1.8853],\n",
       "         [-0.0168, -0.5608]],\n",
       "\n",
       "        [[ 1.6415,  1.8853],\n",
       "         [-0.0168, -0.5608],\n",
       "         [-0.0168, -0.5608]],\n",
       "\n",
       "        [[-0.0168, -0.5608],\n",
       "         [-0.0168, -0.5608],\n",
       "         [-0.7986,  0.5644]],\n",
       "\n",
       "        [[-2.5696,  1.8836],\n",
       "         [-2.5696,  1.8836],\n",
       "         [-2.5696,  1.8836]],\n",
       "\n",
       "        [[-2.5696,  1.8836],\n",
       "         [-2.5696,  1.8836],\n",
       "         [ 0.3323,  1.4900]],\n",
       "\n",
       "        [[-2.5696,  1.8836],\n",
       "         [ 0.3323,  1.4900],\n",
       "         [ 1.8049, -1.0374]],\n",
       "\n",
       "        [[ 0.3323,  1.4900],\n",
       "         [ 1.8049, -1.0374],\n",
       "         [-0.3569,  0.6205]],\n",
       "\n",
       "        [[ 1.8049, -1.0374],\n",
       "         [-0.3569,  0.6205],\n",
       "         [-1.2912,  0.2820]],\n",
       "\n",
       "        [[-0.3569,  0.6205],\n",
       "         [-1.2912,  0.2820],\n",
       "         [-1.2013,  0.2599]],\n",
       "\n",
       "        [[-1.2912,  0.2820],\n",
       "         [-1.2013,  0.2599],\n",
       "         [-0.7986,  0.5644]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X] # All of the same embeddings as in C but rearranged according to X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc44a7",
   "metadata": {},
   "source": [
    "In order to find embedding for 15 from X, I need to use the same \"coordinates\" \n",
    "as for X because arrangement in C[X] is now same as in X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8ef23a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8049, -1.0374])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X][27, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3e2420",
   "metadata": {},
   "source": [
    "To compare let's see what the embedding is for char 15 in original C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46f3315e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8049, -1.0374])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeddings match\n",
    "C[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9daf9c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding layer\n",
    "emb = C[X]\n",
    "\n",
    "#hidden layer\n",
    "W1 = torch. randn((6, 100))\n",
    "b1 = torch.randn(100)\n",
    "\n",
    "h = torch.tanh(emb.view(-1,6) @ W1 + b1)\n",
    "\n",
    "W2 = torch.randn((100, len(chars)))\n",
    "b2 = torch.randn(len(chars))\n",
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5c29c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a1f1136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 27])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2995ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40be0d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60502fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = counts / counts.sum(-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6879320c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6af1844a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f67c60b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0608e-16, 5.4552e-12, 1.4589e-07, 3.7226e-05, 4.8107e-02, 5.8659e-12,\n",
       "         9.8856e-02, 3.3001e-07, 4.2171e-03, 6.2238e-07, 8.7737e-08, 9.2304e-06,\n",
       "         9.8766e-07, 5.0686e-09, 2.5488e-18, 1.5484e-08, 2.5769e-05, 8.7753e-03,\n",
       "         7.7625e-07, 6.5758e-11, 1.1112e-14, 8.3958e-01, 9.6874e-06, 2.3395e-08,\n",
       "         3.6866e-04, 6.5067e-06, 1.6264e-06],\n",
       "        [2.2629e-08, 9.9379e-10, 5.4140e-04, 1.1289e-13, 9.6184e-03, 1.3870e-15,\n",
       "         2.8359e-07, 1.6867e-02, 1.5180e-02, 9.5577e-01, 3.6761e-07, 1.9454e-16,\n",
       "         6.5284e-05, 9.9104e-15, 5.0672e-20, 1.6652e-10, 1.6989e-08, 3.2647e-04,\n",
       "         1.0923e-03, 3.5970e-11, 4.1768e-06, 5.3674e-04, 5.7364e-17, 5.9972e-09,\n",
       "         7.7614e-08, 2.2978e-09, 1.1317e-10],\n",
       "        [8.6674e-11, 1.9722e-08, 8.4828e-07, 5.6350e-04, 4.9965e-04, 1.4831e-09,\n",
       "         1.4171e-01, 1.9999e-06, 1.1465e-07, 4.6735e-07, 2.2063e-08, 2.3843e-12,\n",
       "         4.2572e-06, 2.7200e-09, 1.5166e-10, 6.4733e-08, 8.3499e-08, 8.5717e-01,\n",
       "         1.1007e-10, 7.9480e-08, 2.1323e-17, 1.4131e-08, 6.8096e-09, 5.0006e-10,\n",
       "         8.9253e-13, 4.2222e-05, 2.2877e-11],\n",
       "        [1.2773e-10, 1.9505e-09, 3.8490e-06, 3.4920e-01, 1.0006e-11, 7.1667e-03,\n",
       "         3.3750e-09, 1.1244e-16, 1.9774e-13, 2.5847e-19, 1.7865e-05, 3.3115e-03,\n",
       "         6.4030e-01, 6.9009e-08, 2.8515e-06, 1.1878e-06, 1.2668e-10, 1.3845e-10,\n",
       "         1.0242e-12, 2.3100e-09, 5.7996e-16, 6.6413e-12, 2.5505e-06, 7.5040e-12,\n",
       "         1.2086e-07, 2.8284e-07, 9.9295e-15],\n",
       "        [1.4022e-10, 7.7833e-11, 1.9704e-06, 3.1289e-06, 2.0658e-03, 4.3676e-06,\n",
       "         1.2755e-04, 7.5146e-06, 6.5840e-05, 1.9245e-07, 1.9969e-03, 6.1065e-07,\n",
       "         8.1634e-03, 7.3249e-04, 5.8435e-09, 1.9281e-05, 1.3789e-06, 4.5469e-07,\n",
       "         3.9918e-06, 1.3947e-09, 1.1931e-10, 6.7982e-01, 2.0438e-07, 8.9588e-07,\n",
       "         9.2345e-04, 6.1665e-04, 3.0544e-01],\n",
       "        [2.0608e-16, 5.4552e-12, 1.4589e-07, 3.7226e-05, 4.8107e-02, 5.8659e-12,\n",
       "         9.8856e-02, 3.3001e-07, 4.2171e-03, 6.2238e-07, 8.7737e-08, 9.2304e-06,\n",
       "         9.8766e-07, 5.0686e-09, 2.5488e-18, 1.5484e-08, 2.5769e-05, 8.7753e-03,\n",
       "         7.7625e-07, 6.5758e-11, 1.1112e-14, 8.3958e-01, 9.6874e-06, 2.3395e-08,\n",
       "         3.6866e-04, 6.5067e-06, 1.6264e-06],\n",
       "        [9.4473e-08, 3.2559e-07, 9.5055e-01, 7.6920e-10, 5.9779e-03, 6.7132e-12,\n",
       "         2.7612e-09, 3.6841e-02, 8.0683e-04, 5.6139e-03, 2.0270e-08, 1.7784e-13,\n",
       "         1.1791e-04, 9.3054e-14, 1.6877e-13, 3.5555e-09, 5.1012e-09, 1.6938e-05,\n",
       "         5.3232e-09, 2.2231e-10, 2.3056e-09, 3.7406e-07, 1.5126e-16, 2.5156e-08,\n",
       "         5.9982e-12, 7.7882e-05, 2.6657e-13],\n",
       "        [5.1017e-09, 4.3005e-13, 2.3625e-10, 3.4954e-08, 2.0257e-08, 3.8960e-10,\n",
       "         4.5818e-10, 3.3761e-01, 4.1970e-11, 2.6776e-07, 2.4318e-06, 5.1966e-12,\n",
       "         5.6087e-01, 3.1573e-08, 3.3390e-07, 1.3484e-11, 8.4843e-10, 1.0151e-01,\n",
       "         1.5015e-14, 7.8764e-10, 2.3949e-16, 7.4353e-08, 4.5223e-13, 6.9407e-13,\n",
       "         1.2683e-13, 3.6335e-12, 3.9954e-10],\n",
       "        [5.0082e-11, 1.0864e-08, 8.6102e-12, 5.3557e-05, 2.6338e-18, 1.6835e-06,\n",
       "         7.8602e-05, 7.2939e-12, 9.9023e-10, 1.5669e-13, 1.8482e-04, 1.9752e-03,\n",
       "         4.3215e-13, 2.8268e-04, 4.0560e-05, 2.5514e-03, 4.4061e-09, 3.2674e-13,\n",
       "         2.3808e-04, 4.4757e-05, 1.2662e-08, 8.3517e-08, 9.9285e-01, 5.0025e-09,\n",
       "         1.6893e-03, 5.4549e-06, 5.5684e-09],\n",
       "        [2.4019e-03, 1.0464e-05, 4.0767e-02, 2.5967e-12, 1.3771e-07, 1.5719e-10,\n",
       "         2.5981e-08, 9.3872e-01, 5.2159e-04, 2.0403e-06, 9.0769e-04, 3.6278e-12,\n",
       "         3.8785e-11, 9.4625e-10, 5.3746e-09, 4.1109e-07, 2.3707e-05, 1.6223e-06,\n",
       "         1.3712e-02, 1.2905e-06, 9.3912e-06, 4.2140e-05, 1.4753e-14, 1.1764e-06,\n",
       "         2.8141e-03, 6.6045e-05, 1.3830e-06],\n",
       "        [3.1274e-11, 5.0384e-09, 5.1154e-14, 4.2871e-03, 3.7691e-06, 1.0096e-05,\n",
       "         4.0563e-02, 2.3632e-02, 4.4932e-06, 3.7875e-04, 8.3091e-01, 1.8451e-07,\n",
       "         1.6815e-02, 8.0742e-02, 4.4218e-06, 2.4166e-06, 8.8791e-08, 1.0146e-03,\n",
       "         1.4961e-07, 5.8951e-07, 1.0489e-12, 1.5099e-03, 1.1428e-04, 8.8572e-11,\n",
       "         2.2108e-09, 4.9876e-06, 2.3150e-09],\n",
       "        [1.7851e-15, 3.3484e-10, 7.6251e-08, 2.1803e-10, 2.8342e-15, 4.1721e-08,\n",
       "         1.3516e-06, 4.8209e-12, 1.2627e-08, 1.4635e-14, 1.0413e-02, 2.4438e-05,\n",
       "         7.4642e-13, 4.9139e-05, 6.6455e-09, 2.7538e-03, 1.3562e-06, 5.7995e-11,\n",
       "         2.9866e-04, 1.2220e-08, 2.1152e-07, 2.0848e-05, 6.4721e-08, 1.4667e-09,\n",
       "         9.8445e-01, 1.9865e-03, 8.6526e-08],\n",
       "        [2.0608e-16, 5.4552e-12, 1.4589e-07, 3.7226e-05, 4.8107e-02, 5.8659e-12,\n",
       "         9.8856e-02, 3.3001e-07, 4.2171e-03, 6.2238e-07, 8.7737e-08, 9.2304e-06,\n",
       "         9.8766e-07, 5.0686e-09, 2.5488e-18, 1.5484e-08, 2.5769e-05, 8.7753e-03,\n",
       "         7.7625e-07, 6.5758e-11, 1.1112e-14, 8.3958e-01, 9.6874e-06, 2.3395e-08,\n",
       "         3.6866e-04, 6.5067e-06, 1.6264e-06],\n",
       "        [8.2111e-14, 6.7057e-10, 1.5401e-05, 4.4882e-06, 2.0465e-01, 1.4847e-12,\n",
       "         5.1703e-01, 1.4115e-03, 2.0471e-04, 8.0530e-06, 1.5966e-06, 1.2992e-10,\n",
       "         1.0988e-05, 3.0589e-13, 9.5421e-18, 2.6098e-06, 2.6034e-05, 2.9492e-02,\n",
       "         4.9702e-05, 1.9921e-10, 7.5725e-13, 2.4704e-01, 1.1281e-09, 7.2179e-08,\n",
       "         1.9888e-08, 4.6483e-05, 8.6649e-09],\n",
       "        [8.4941e-08, 1.4628e-10, 1.2862e-01, 1.3167e-11, 3.2146e-02, 1.3641e-10,\n",
       "         2.1545e-09, 7.6973e-01, 1.7126e-06, 1.5054e-02, 7.1111e-06, 6.0384e-15,\n",
       "         1.1195e-02, 4.3082e-11, 6.2359e-15, 4.6874e-09, 4.8022e-11, 4.3245e-02,\n",
       "         6.4145e-11, 8.1896e-10, 2.9319e-08, 6.0472e-07, 4.4746e-17, 3.9262e-10,\n",
       "         2.8305e-12, 1.4219e-07, 1.7847e-13],\n",
       "        [1.3554e-10, 1.5162e-07, 2.6842e-13, 6.4938e-05, 3.3407e-07, 1.0786e-06,\n",
       "         7.3452e-05, 9.8230e-03, 9.1699e-05, 1.8477e-05, 9.0337e-01, 3.3826e-07,\n",
       "         4.3195e-02, 4.2141e-02, 1.8297e-04, 1.0474e-06, 1.7446e-08, 1.3387e-05,\n",
       "         1.9508e-05, 1.6526e-06, 2.2346e-10, 1.0020e-03, 6.3230e-08, 2.7743e-10,\n",
       "         4.6800e-07, 1.3540e-07, 3.4691e-09],\n",
       "        [2.0608e-16, 5.4552e-12, 1.4589e-07, 3.7226e-05, 4.8107e-02, 5.8659e-12,\n",
       "         9.8856e-02, 3.3001e-07, 4.2171e-03, 6.2238e-07, 8.7737e-08, 9.2304e-06,\n",
       "         9.8766e-07, 5.0686e-09, 2.5488e-18, 1.5484e-08, 2.5769e-05, 8.7753e-03,\n",
       "         7.7625e-07, 6.5758e-11, 1.1112e-14, 8.3958e-01, 9.6874e-06, 2.3395e-08,\n",
       "         3.6866e-04, 6.5067e-06, 1.6264e-06],\n",
       "        [1.6418e-14, 2.2010e-10, 1.6477e-06, 1.3411e-05, 5.1265e-01, 5.0013e-13,\n",
       "         1.2968e-01, 9.0942e-05, 5.9029e-06, 2.4207e-07, 1.3144e-06, 7.3235e-10,\n",
       "         1.9209e-05, 5.7824e-14, 8.3341e-19, 3.5435e-05, 1.7824e-05, 3.1589e-01,\n",
       "         6.6243e-07, 5.2502e-11, 6.0503e-16, 4.1534e-02, 1.3678e-09, 1.5915e-08,\n",
       "         5.8826e-10, 5.1796e-05, 4.8112e-09],\n",
       "        [3.8173e-09, 4.0572e-11, 3.1733e-03, 1.1451e-11, 2.2765e-06, 3.2672e-12,\n",
       "         2.5757e-08, 1.7470e-02, 6.0837e-05, 9.0772e-04, 1.0761e-08, 7.9664e-15,\n",
       "         1.3136e-02, 1.3293e-09, 5.0303e-16, 3.2853e-09, 1.2654e-10, 2.5871e-01,\n",
       "         4.6813e-10, 2.1368e-15, 3.5685e-08, 7.0654e-01, 1.4337e-14, 1.8871e-09,\n",
       "         7.5564e-11, 8.6491e-09, 1.4702e-08],\n",
       "        [2.3625e-17, 3.1821e-10, 5.8084e-10, 1.4340e-11, 1.4134e-07, 2.3736e-14,\n",
       "         9.9191e-01, 2.3746e-07, 8.7351e-07, 9.4539e-09, 2.8859e-06, 2.1152e-10,\n",
       "         3.8720e-10, 9.0111e-10, 5.1676e-17, 4.7807e-09, 5.6543e-07, 3.3355e-04,\n",
       "         3.0847e-07, 1.3628e-09, 1.0319e-11, 7.7039e-03, 5.4463e-12, 1.9854e-09,\n",
       "         3.5458e-07, 4.3585e-05, 1.5397e-09],\n",
       "        [3.3945e-10, 7.1916e-05, 6.3152e-08, 2.8749e-11, 1.6191e-13, 1.4139e-13,\n",
       "         2.0602e-11, 7.1972e-06, 1.1425e-02, 7.8723e-07, 5.3909e-01, 8.3094e-09,\n",
       "         6.6386e-04, 1.7025e-06, 3.0794e-10, 3.2479e-08, 4.9679e-11, 9.5767e-10,\n",
       "         1.0693e-01, 2.0430e-08, 2.3151e-03, 4.5188e-07, 9.4099e-08, 3.4358e-07,\n",
       "         3.3949e-01, 9.2439e-08, 6.9617e-14],\n",
       "        [7.8592e-08, 3.5288e-04, 5.6938e-09, 5.0898e-17, 9.1687e-13, 1.0333e-15,\n",
       "         1.5172e-08, 4.5549e-03, 8.9252e-01, 4.9034e-04, 3.8995e-06, 6.7140e-14,\n",
       "         4.2772e-08, 5.4007e-10, 8.6163e-10, 1.8736e-10, 8.9944e-11, 6.5589e-05,\n",
       "         1.5036e-02, 1.1806e-06, 8.6045e-02, 2.8025e-04, 2.2356e-12, 2.7468e-08,\n",
       "         6.4818e-04, 8.5412e-08, 2.2431e-13],\n",
       "        [3.2309e-03, 1.8518e-02, 7.6049e-08, 1.6591e-07, 1.3622e-11, 9.1004e-08,\n",
       "         3.3108e-05, 6.1639e-07, 3.7162e-10, 3.5106e-09, 6.2996e-04, 2.6948e-07,\n",
       "         3.6006e-07, 5.2779e-09, 1.5232e-04, 1.4889e-07, 4.7695e-09, 9.7435e-01,\n",
       "         1.8263e-03, 1.2591e-03, 8.4488e-12, 8.6425e-08, 5.3004e-11, 2.9096e-09,\n",
       "         2.6841e-06, 1.2269e-07, 5.9038e-14],\n",
       "        [6.2123e-03, 7.0507e-05, 2.4930e-09, 5.7187e-05, 4.2696e-14, 6.1632e-04,\n",
       "         2.5409e-11, 1.7530e-10, 1.1046e-12, 2.2706e-15, 4.1122e-01, 7.2645e-04,\n",
       "         1.4368e-03, 1.2774e-06, 5.7964e-01, 7.1188e-06, 7.8148e-09, 7.5592e-10,\n",
       "         3.1331e-09, 5.4698e-07, 1.7402e-08, 1.8107e-10, 5.1647e-07, 2.8953e-10,\n",
       "         8.3379e-06, 2.0151e-08, 1.3692e-16],\n",
       "        [1.4500e-14, 1.0401e-09, 1.4914e-12, 5.2026e-07, 4.2704e-10, 1.1962e-05,\n",
       "         8.6548e-01, 6.7028e-11, 2.5729e-06, 6.2047e-09, 5.6675e-03, 2.1114e-06,\n",
       "         9.5343e-07, 1.2372e-01, 5.0741e-10, 4.8032e-05, 5.0769e-09, 5.3779e-08,\n",
       "         1.3419e-04, 9.3396e-08, 2.4144e-09, 3.6436e-03, 3.0123e-04, 1.1199e-08,\n",
       "         9.2161e-04, 4.8120e-05, 1.3478e-05],\n",
       "        [2.0608e-16, 5.4552e-12, 1.4589e-07, 3.7226e-05, 4.8107e-02, 5.8659e-12,\n",
       "         9.8856e-02, 3.3001e-07, 4.2171e-03, 6.2238e-07, 8.7737e-08, 9.2304e-06,\n",
       "         9.8766e-07, 5.0686e-09, 2.5488e-18, 1.5484e-08, 2.5769e-05, 8.7753e-03,\n",
       "         7.7625e-07, 6.5758e-11, 1.1112e-14, 8.3958e-01, 9.6874e-06, 2.3395e-08,\n",
       "         3.6866e-04, 6.5067e-06, 1.6264e-06],\n",
       "        [7.4370e-10, 9.9542e-10, 2.4616e-03, 6.1329e-11, 1.9479e-02, 3.4478e-15,\n",
       "         4.2916e-06, 1.0324e-03, 2.4157e-03, 4.0808e-03, 3.3611e-08, 2.6507e-15,\n",
       "         2.7052e-05, 2.3902e-14, 1.1875e-19, 6.1124e-10, 1.0915e-08, 4.1765e-04,\n",
       "         7.2734e-05, 2.5148e-11, 1.5345e-09, 9.7001e-01, 4.3044e-14, 5.3828e-09,\n",
       "         6.8272e-08, 2.0814e-07, 1.5208e-08],\n",
       "        [1.5412e-07, 1.4537e-09, 7.4886e-06, 1.5171e-11, 3.5570e-03, 2.8263e-13,\n",
       "         1.5412e-11, 9.1485e-02, 1.6023e-09, 1.7961e-06, 1.2734e-08, 4.9217e-17,\n",
       "         9.7039e-04, 9.1228e-15, 2.1164e-14, 2.7028e-12, 1.8430e-10, 9.0395e-01,\n",
       "         4.7343e-12, 3.2712e-05, 6.9770e-13, 5.3813e-10, 2.4101e-19, 8.9626e-11,\n",
       "         3.5748e-13, 2.4842e-09, 1.3477e-10],\n",
       "        [7.7369e-09, 1.5201e-08, 9.4781e-14, 4.1871e-06, 4.8998e-12, 2.0129e-07,\n",
       "         4.6130e-11, 7.1013e-08, 2.4111e-09, 2.1146e-09, 9.2319e-04, 9.3916e-07,\n",
       "         6.7738e-02, 6.9831e-04, 9.3062e-01, 1.0819e-05, 1.7367e-09, 1.4802e-09,\n",
       "         2.4482e-07, 1.1893e-07, 2.3712e-11, 1.2826e-09, 3.7449e-10, 1.4361e-07,\n",
       "         8.1915e-09, 6.4629e-11, 4.1923e-12],\n",
       "        [1.2268e-12, 9.4038e-09, 2.6861e-09, 2.1881e-08, 2.2929e-15, 1.0455e-08,\n",
       "         1.4061e-02, 1.3398e-10, 6.0969e-08, 1.4383e-13, 4.6318e-05, 1.1500e-04,\n",
       "         7.3785e-17, 8.3086e-05, 4.6398e-08, 8.9159e-02, 4.4868e-05, 2.4035e-11,\n",
       "         1.7102e-01, 3.3132e-03, 1.0031e-05, 2.8592e-07, 1.8218e-03, 1.3047e-10,\n",
       "         7.0828e-03, 7.1324e-01, 8.2276e-10],\n",
       "        [4.4349e-16, 6.9043e-10, 2.6127e-08, 1.1163e-02, 8.6124e-05, 1.5905e-07,\n",
       "         1.9193e-02, 1.9384e-07, 7.1328e-07, 8.6206e-12, 8.5771e-01, 2.9266e-06,\n",
       "         1.7612e-04, 8.2961e-05, 1.4850e-11, 1.2631e-05, 9.4982e-06, 5.7557e-05,\n",
       "         1.7316e-06, 2.9091e-10, 7.4284e-13, 1.0853e-01, 1.0103e-06, 2.4346e-06,\n",
       "         1.8449e-03, 1.1233e-03, 3.3078e-07],\n",
       "        [1.2019e-13, 1.5422e-10, 5.8679e-08, 1.0217e-07, 1.8026e-05, 2.3931e-09,\n",
       "         1.6583e-03, 3.6290e-05, 4.5347e-05, 8.8028e-09, 1.3116e-03, 2.1339e-07,\n",
       "         1.8818e-06, 6.4568e-07, 2.9191e-14, 7.5109e-07, 3.8357e-06, 1.1213e-04,\n",
       "         1.4162e-04, 1.7399e-11, 1.6491e-14, 9.9650e-01, 1.4539e-09, 5.6270e-09,\n",
       "         1.5005e-04, 1.5005e-05, 3.7379e-06]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644a3a31",
   "metadata": {},
   "source": [
    "<a name='3-3'></a>\n",
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfd2b3e",
   "metadata": {},
   "source": [
    "Now to evaluate the prediction of the forward pass above, we need to get the probabilities predicted for the Y vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed22b6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca4ffbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.8659e-12, 9.9104e-15, 2.7200e-09, 1.9505e-09, 1.4022e-10, 1.5484e-08,\n",
       "        1.1791e-04, 2.6776e-07, 9.9285e-01, 2.0403e-06, 5.0384e-09, 1.7851e-15,\n",
       "        5.4552e-12, 1.1281e-09, 1.4628e-10, 1.3554e-10, 6.2238e-07, 5.2502e-11,\n",
       "        4.0572e-11, 5.8084e-10, 1.4139e-13, 4.2772e-08, 3.6006e-07, 7.0507e-05,\n",
       "        1.4500e-14, 6.5758e-11, 6.1124e-10, 1.8430e-10, 2.4111e-09, 1.4383e-13,\n",
       "        6.9043e-10, 1.2019e-13])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[torch.arange(probs.shape[0]), Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e5fd32",
   "metadata": {},
   "source": [
    "These probabilities must be close to one, because Y is the label vector. In fact they are closer to 0. \n",
    "This is because model is untrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ea8ed59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21.0661)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll = -(probs[torch.arange(probs.shape[0]), Y]).log().mean()\n",
    "nll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc29d7e",
   "metadata": {},
   "source": [
    "<a name='3-4'></a>\n",
    "## Improving forward pass and eval code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "dde58b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21.6251, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initiate_params(input_len, hidden_layer_size=100, embedding_size=EMBEDDING_SIZE):\n",
    "    C = torch.randn((input_len, embedding_size), requires_grad=True)\n",
    "    W1 = torch.randn((BLOCK_SIZE*embedding_size, hidden_layer_size), requires_grad=True)\n",
    "    b1 = torch.randn(hidden_layer_size, requires_grad=True)\n",
    "    W2 = torch.randn((hidden_layer_size, input_len), requires_grad=True)\n",
    "    b2 = torch.randn(input_len, requires_grad=True)\n",
    "    \n",
    "    return {'C': C, 'W1': W1, 'W2': W2, 'b1': b1, 'b2': b2}\n",
    "\n",
    "def forward_pass(X, parameters):\n",
    "    C = parameters['C']\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    #embedding layer\n",
    "#     C = torch.randn((len(chars),2), requires_grad=True)\n",
    "    emb = C[X]\n",
    "\n",
    "    #hidden layer\n",
    "#     W1 = torch.randn((6, 100), requires_grad=True)\n",
    "#     b1 = torch.randn(100, requires_grad=True)\n",
    "\n",
    "    h = torch.tanh(emb.view(-1, BLOCK_SIZE*EMBEDDING_SIZE) @ W1 + b1)\n",
    "\n",
    "    #output layer\n",
    "#     W2 = torch.randn((100, len(chars)), requires_grad=True)\n",
    "#     b2 = torch.randn(len(chars), requires_grad=True)\n",
    "    logits = h @ W2 + b2\n",
    "\n",
    "#     parameters = [C, W1, W2, b1, b2]\n",
    "    \n",
    "    return logits\n",
    "\n",
    "parameters = initiate_params(len(chars))\n",
    "logits = forward_pass(X, parameters)\n",
    "\n",
    "#softmax\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(-1, keepdims=True)\n",
    "\n",
    "#loss\n",
    "nll_loss = -(probs[torch.arange(probs.shape[0]), Y]).log().mean()\n",
    "nll_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c564070",
   "metadata": {},
   "source": [
    "Finding softmax and loss calculation could be replaced with crossentropy function from the torch lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60e6e900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.5170, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll_loss = F.cross_entropy(logits, Y)\n",
    "nll_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668f9884",
   "metadata": {},
   "source": [
    "<a name='3-5'></a>\n",
    "## Backprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4468560a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': tensor([[ 0.4507,  1.1964],\n",
       "         [-0.4769,  0.5135],\n",
       "         [ 0.5694,  0.6355],\n",
       "         [ 0.2286, -0.7949],\n",
       "         [-0.2944, -0.3748],\n",
       "         [-0.9036, -1.1943],\n",
       "         [ 0.2421,  2.8643],\n",
       "         [-1.1535,  0.7167],\n",
       "         [ 0.6277, -0.1475],\n",
       "         [ 1.1983, -0.4449],\n",
       "         [ 0.1213,  0.0331],\n",
       "         [-2.2170, -1.0393],\n",
       "         [-0.0744, -1.7911],\n",
       "         [ 1.3047, -0.4856],\n",
       "         [ 2.0280,  0.4876],\n",
       "         [-0.7542,  0.1676],\n",
       "         [-1.4646, -1.3945],\n",
       "         [ 2.3480, -0.0529],\n",
       "         [-1.5569,  0.9921],\n",
       "         [-0.2370, -1.2369],\n",
       "         [ 0.6232, -2.3020],\n",
       "         [-1.1073,  0.6506],\n",
       "         [-0.7354, -0.0967],\n",
       "         [-0.2556, -0.0953],\n",
       "         [-0.6693,  1.2051],\n",
       "         [-1.8134,  0.8517],\n",
       "         [-1.2440,  0.8120]], requires_grad=True),\n",
       " 'W1': tensor([[ 1.2617e+00,  5.2546e-01, -3.6154e-02, -2.1852e-02, -2.2882e-01,\n",
       "           1.4489e+00, -5.9283e-01, -6.6637e-02,  2.2685e+00, -3.9297e-02,\n",
       "          -9.5999e-01, -1.1376e+00,  6.9569e-01, -8.4566e-01, -2.7819e-01,\n",
       "          -3.5161e-01,  5.0749e-01, -6.0752e-01, -2.2401e-01, -5.2774e-02,\n",
       "           2.6626e-01,  1.2916e+00, -9.2434e-02, -3.3301e-01,  1.0947e+00,\n",
       "           8.5047e-01, -1.0975e+00,  7.4317e-01,  1.0677e+00,  1.7884e+00,\n",
       "           8.5570e-01,  9.0322e-01,  2.3225e+00, -9.0496e-01,  5.9030e-01,\n",
       "           8.3042e-01,  3.9822e-01, -1.6672e+00,  1.8020e-01,  4.1485e-01,\n",
       "           2.1706e-01, -1.4572e+00,  7.2543e-01, -1.2598e+00,  5.2145e-01,\n",
       "          -1.9422e+00,  1.0741e+00, -1.0982e+00,  1.9745e-01, -3.3047e-01,\n",
       "           1.1864e+00,  2.3502e-01, -4.9985e-01,  2.8234e+00,  1.1987e+00,\n",
       "          -4.0729e-01, -4.6449e-01, -5.7610e-01,  6.8353e-01,  4.8477e-01,\n",
       "           5.9126e-01,  7.3595e-01,  3.7290e-01,  9.8600e-01,  1.7597e+00,\n",
       "          -2.0257e+00, -7.6115e-01,  1.2476e+00, -5.2712e-02, -2.0797e+00,\n",
       "           2.8207e-01,  1.4914e+00,  5.2354e-01, -2.3045e+00, -4.2781e-01,\n",
       "          -1.1794e+00,  4.6215e-01, -8.0317e-02,  1.1177e+00, -2.6513e-01,\n",
       "           1.6569e+00, -7.0299e-01,  1.3739e+00, -3.9848e-01,  5.0178e-01,\n",
       "           7.5298e-01, -4.5061e-01, -7.4556e-01, -1.7493e+00,  1.5744e+00,\n",
       "          -2.3250e-01, -1.0659e+00, -1.3307e+00,  7.2555e-01, -4.4516e-01,\n",
       "           8.0293e-02,  1.7942e-01,  7.3673e-01,  1.9382e-01, -1.6897e+00],\n",
       "         [ 3.5512e-01,  3.6462e-01,  5.2825e-01, -1.2085e-01,  2.5810e-01,\n",
       "          -5.0659e-01,  2.3264e-04,  1.2775e-01,  2.1426e-01, -5.9519e-01,\n",
       "           3.0653e-01,  1.5073e-01,  3.0340e-01, -1.2383e+00, -1.7281e+00,\n",
       "           1.4863e-01, -2.6779e-01, -6.9732e-01,  3.4555e-01,  9.3378e-02,\n",
       "           1.5866e-01,  2.3513e-01, -1.1620e+00, -1.6662e-01,  1.0637e+00,\n",
       "           2.7123e-01,  4.4295e-01, -1.8506e-01,  4.2447e-01, -5.0840e-01,\n",
       "           6.9239e-01, -1.0907e+00, -1.9811e-01,  1.9717e-01,  1.5425e+00,\n",
       "           2.0168e+00, -1.6588e-01,  1.3760e+00, -1.0074e+00,  2.2881e-01,\n",
       "          -1.0903e+00, -3.6595e-01,  6.0369e-01, -2.5924e-01, -9.3890e-01,\n",
       "           1.4032e+00,  8.6402e-01, -8.1788e-01, -2.5796e-01,  8.3994e-03,\n",
       "          -2.5734e+00, -1.9205e-01, -4.2114e-01,  1.2465e+00, -1.9824e+00,\n",
       "           7.0080e-01,  9.5050e-01,  9.6090e-01, -7.0641e-01,  1.5721e+00,\n",
       "          -1.5035e-01,  6.5217e-01,  7.5386e-02, -7.9104e-01, -1.2278e+00,\n",
       "          -7.9996e-01,  2.5988e-02,  1.6876e+00,  7.7409e-01, -1.0104e+00,\n",
       "           1.0888e+00, -1.9128e+00,  6.1604e-01, -9.9334e-02,  2.7825e-01,\n",
       "           3.5787e-01, -5.0941e-01,  9.0613e-02,  3.3612e-01, -1.9614e+00,\n",
       "          -8.8184e-01,  4.1495e-01,  2.8574e+00, -6.5963e-02, -8.5034e-01,\n",
       "           1.4171e+00,  1.9076e-01, -3.3410e-01, -6.5175e-01, -5.4786e-01,\n",
       "           1.1988e+00,  1.4754e+00, -3.4005e-01,  1.9133e-02, -1.8021e-01,\n",
       "          -2.6018e-01,  3.2453e-01, -7.0085e-01, -2.3893e-01, -2.6882e+00],\n",
       "         [ 3.0005e-01, -8.2506e-01, -2.9920e+00,  3.7119e-04,  1.1190e-01,\n",
       "           1.3258e+00,  9.3715e-01,  9.0214e-01, -1.0722e+00, -5.9114e-01,\n",
       "           2.7639e-01,  6.8270e-01, -1.3790e+00,  5.0091e-01, -1.3961e+00,\n",
       "           1.1474e+00,  1.5526e+00,  2.4680e+00,  1.6428e-01, -1.7265e+00,\n",
       "          -7.4233e-01, -1.4765e+00,  2.8415e-01, -1.0454e+00,  4.7795e-01,\n",
       "          -2.0431e+00, -8.0274e-01,  1.6801e+00,  8.0509e-01, -3.1619e-01,\n",
       "          -4.2273e-02,  1.4008e+00,  1.4689e+00, -1.0186e+00,  1.0505e+00,\n",
       "           4.0859e-01,  6.5382e-01, -5.9515e-01,  1.8882e+00, -2.1391e+00,\n",
       "          -5.1004e-01,  2.6225e-02, -1.3893e+00, -6.0035e-01,  7.8256e-02,\n",
       "           9.6542e-02, -1.8884e-01,  8.6028e-01,  1.0684e-01,  9.8592e-01,\n",
       "          -9.8018e-01, -8.2562e-01, -7.9283e-01, -1.4002e+00, -3.3436e-01,\n",
       "          -4.8726e-01,  4.7471e-01, -1.7602e+00, -1.1514e+00, -6.6453e-01,\n",
       "          -1.3048e+00, -7.9757e-01,  3.6556e-01,  1.6910e+00, -1.7019e+00,\n",
       "           7.8118e-01,  8.6239e-02, -2.9754e-01, -8.4300e-01,  3.7046e-01,\n",
       "          -6.8595e-01,  1.1502e-01, -1.0305e+00, -4.3534e-01, -1.4283e+00,\n",
       "          -1.1261e+00, -2.7888e-01,  1.8689e+00,  6.1039e-01,  1.5801e-01,\n",
       "          -9.6270e-01,  5.6495e-01, -9.0398e-01,  1.1315e+00,  5.9442e-01,\n",
       "          -5.1003e-01, -1.8153e-01,  8.4081e-01, -8.7940e-01, -8.2736e-01,\n",
       "           2.9502e-01,  1.3061e+00,  2.8481e-01, -1.5695e+00, -4.6293e-01,\n",
       "          -2.4665e+00, -2.0508e+00, -9.4035e-01, -3.1124e-01, -1.6810e-01],\n",
       "         [ 9.1929e-02, -6.6622e-01, -3.2666e-01,  2.8494e-01,  8.1144e-02,\n",
       "           4.5655e-01,  2.4025e+00,  1.1031e+00, -1.8078e+00, -3.0747e-01,\n",
       "           1.1902e+00,  2.7122e-01,  2.6048e-01,  1.6396e-01, -1.2560e+00,\n",
       "          -2.4469e-01,  6.7154e-02,  3.0270e-02,  9.6376e-01, -2.1284e+00,\n",
       "           1.4381e+00, -1.7330e-01,  4.3135e-01, -5.6547e-01,  2.2543e+00,\n",
       "           4.1078e-01,  4.3851e-01, -1.2024e+00, -1.2761e+00, -1.5186e+00,\n",
       "          -1.2972e+00, -1.1877e+00, -5.9516e-01, -6.8568e-01, -1.2563e+00,\n",
       "          -1.3296e+00,  5.3786e-01, -7.7345e-01, -1.1600e+00, -6.3567e-01,\n",
       "          -2.4838e-01,  2.4030e-01,  1.0886e+00, -7.9709e-01, -3.9666e-01,\n",
       "           1.8104e+00,  1.2011e+00, -2.8113e-02,  5.0276e-01,  4.5637e-01,\n",
       "          -1.2012e+00,  5.5697e-02, -1.7865e-01,  8.0485e-01, -1.0747e+00,\n",
       "           6.2263e-01, -1.2452e-01, -3.5605e-01,  1.1642e+00,  1.2655e+00,\n",
       "          -9.5613e-01,  8.7197e-01, -1.5639e+00, -7.4201e-01, -4.7391e-01,\n",
       "          -3.9677e-02,  2.7708e+00, -1.7967e-01, -6.8061e-01, -2.0414e-01,\n",
       "           2.9421e-01, -1.0012e+00,  1.2976e-01, -5.3630e-02, -5.4088e-01,\n",
       "           3.8019e-01, -1.3571e+00, -6.9846e-01,  5.3299e-01,  4.7049e-01,\n",
       "           1.5396e-01, -7.7407e-01, -9.0765e-01,  4.9248e-01, -2.8491e-01,\n",
       "           9.9574e-01, -4.2951e-01, -1.4739e+00,  1.0970e+00,  1.7191e-01,\n",
       "           3.8378e-02,  1.0087e+00, -2.1709e-01,  4.8106e-02,  2.7363e-02,\n",
       "           1.0929e+00,  1.3200e+00,  1.7856e+00, -4.0284e-01, -4.9507e-01],\n",
       "         [ 1.1229e+00,  6.1111e-01, -1.2253e+00, -1.7709e-01,  5.0090e-01,\n",
       "           1.6551e+00,  1.4704e-01,  3.0011e-01,  1.1799e+00,  2.5634e-01,\n",
       "          -3.1733e-01, -1.1234e+00, -8.8231e-01, -8.8534e-01, -8.5472e-01,\n",
       "           1.3961e+00,  1.0514e+00,  1.5531e+00, -3.2973e-02, -9.4939e-01,\n",
       "          -3.7587e-01,  1.2365e-01,  4.3765e-01,  6.6052e-01,  3.5547e-01,\n",
       "          -1.5324e+00,  6.7121e-01, -3.5574e-01, -4.1125e-01, -2.8536e-01,\n",
       "          -1.1771e+00,  3.7209e-01,  6.5853e-01,  2.0130e+00,  3.1628e+00,\n",
       "           2.7057e+00,  7.8773e-01, -2.2994e-02,  1.0364e+00,  3.3395e-01,\n",
       "           9.5647e-01,  7.9550e-01, -1.4754e+00, -6.7619e-01,  8.3477e-01,\n",
       "          -5.0524e-01,  8.7512e-01,  1.1182e+00, -1.1427e+00,  2.9291e-01,\n",
       "          -1.3930e-02, -6.0816e-01, -7.3512e-01, -4.7345e-03, -3.3849e-01,\n",
       "          -2.6850e+00,  5.5912e-01, -1.5030e+00,  1.8357e-01, -2.0128e-01,\n",
       "           1.9146e+00, -4.3010e-01, -1.9681e+00,  8.3751e-01, -1.2638e+00,\n",
       "          -8.3487e-01,  8.9665e-01,  6.1583e-02, -1.9168e+00, -8.6394e-01,\n",
       "           5.2629e-01, -8.5283e-02,  1.0054e+00,  7.4787e-01,  5.4111e-01,\n",
       "          -1.1018e-01, -5.7301e-01, -1.1901e+00, -1.8941e-01,  8.6365e-01,\n",
       "          -5.7339e-02, -7.3920e-01,  4.9634e-01, -6.5699e-02, -1.3608e+00,\n",
       "           2.1914e-01,  3.8455e-01,  3.8656e-01,  2.1898e-01,  6.6224e-01,\n",
       "           3.0999e-01,  1.2949e+00,  6.3599e-01,  8.3730e-01, -3.1320e-01,\n",
       "          -7.3791e-01, -7.0718e-01,  3.5155e+00, -2.8128e-01, -1.8938e-01],\n",
       "         [-1.1770e-01,  8.8244e-01,  3.3212e-01,  4.9132e-01,  3.4149e-01,\n",
       "           1.6294e-01,  1.0134e+00, -1.8059e+00,  7.9127e-01, -6.0438e-01,\n",
       "          -1.1680e+00,  6.7099e-01, -1.8127e+00,  2.0796e+00, -3.6603e-01,\n",
       "          -1.1213e+00,  1.1134e+00, -1.8548e-01,  8.0689e-01,  6.7414e-01,\n",
       "          -7.4589e-01, -1.5016e+00,  1.5203e+00, -7.9619e-01,  2.2042e-01,\n",
       "           1.3373e+00,  2.8668e-01, -3.7561e-01,  7.7431e-01, -3.7282e-01,\n",
       "           1.2850e-01, -9.1556e-01, -1.5654e+00,  3.5640e-01, -7.6905e-01,\n",
       "           2.1855e+00, -7.4368e-01, -1.3614e+00, -2.8120e+00,  4.5036e-01,\n",
       "           7.0563e-01, -3.3433e-01, -1.5975e-01, -7.6625e-01, -7.2170e-01,\n",
       "          -4.6058e-01, -1.1735e-01, -1.2518e+00, -9.4800e-01, -6.2755e-01,\n",
       "          -7.3516e-01,  8.5965e-01, -1.5099e+00, -2.7723e-01,  1.5159e+00,\n",
       "           7.9259e-01,  2.0864e+00, -1.0367e+00, -8.5307e-01,  5.9362e-01,\n",
       "           1.4501e-01,  3.8129e-01,  3.1685e-02,  1.8953e+00, -3.7143e-01,\n",
       "          -4.7219e-01,  2.6173e-01, -6.4124e-01, -5.5051e-01, -1.6496e-01,\n",
       "          -5.1254e-01, -1.1196e+00,  1.0508e+00, -6.7626e-01,  6.2725e-01,\n",
       "          -1.2256e-01, -6.1627e-01, -8.5289e-01,  1.3516e+00, -8.4919e-01,\n",
       "          -8.5526e-01,  4.1461e-01,  2.4713e-01, -5.6734e-01,  4.6424e-01,\n",
       "          -1.2590e+00,  5.9029e-01, -2.1969e-01,  1.1994e+00, -8.5222e-02,\n",
       "           1.3991e+00,  5.9835e-01, -3.8301e-01, -5.1402e-01,  1.4255e+00,\n",
       "           1.1632e+00, -9.9004e-01,  1.5221e+00,  2.7140e-01, -6.3167e-02]],\n",
       "        requires_grad=True),\n",
       " 'W2': tensor([[-0.8571, -1.7331,  0.1695,  ..., -1.4198,  0.3259, -0.0258],\n",
       "         [ 2.2277, -0.8516,  0.4434,  ..., -1.2699, -1.3230,  0.2233],\n",
       "         [-0.8266, -0.3656, -0.8948,  ...,  0.4927, -0.5116,  1.7600],\n",
       "         ...,\n",
       "         [-0.3881,  2.0984, -0.9075,  ...,  0.3653, -1.0979, -2.0138],\n",
       "         [ 1.0921,  0.2971,  2.0032,  ...,  0.4385, -0.6455,  1.0179],\n",
       "         [-1.9156,  0.9083,  1.1531,  ...,  0.1337,  1.6325, -1.2922]],\n",
       "        requires_grad=True),\n",
       " 'b1': tensor([-1.5119e+00, -8.5262e-01, -1.6092e-01,  8.7254e-01,  5.0494e-01,\n",
       "         -5.5079e-01, -6.4266e-01, -1.6028e+00, -6.2990e-01, -1.0593e-02,\n",
       "          8.0824e-01, -4.7089e-01, -1.1917e-01,  5.0602e-01,  1.3819e-02,\n",
       "         -1.5730e+00, -2.7825e+00,  2.4499e+00,  3.2417e-01,  1.1254e+00,\n",
       "          1.9391e+00,  7.9932e-01, -2.7944e-02,  7.4440e-01,  5.3324e-01,\n",
       "         -6.4130e-01,  1.7839e+00, -1.4150e+00,  5.5101e-01, -4.7134e-01,\n",
       "          3.5400e-02,  8.3510e-03,  7.5144e-01,  2.0064e-01,  6.0167e-01,\n",
       "          3.4255e-01, -1.4035e+00, -6.5892e-01,  6.5854e-01, -1.4960e+00,\n",
       "         -5.5976e-01, -7.1499e-01, -6.7393e-01,  4.1280e-01, -3.4199e-01,\n",
       "         -3.5342e-01,  1.4405e+00, -1.2157e+00, -4.5223e-01, -3.8476e-01,\n",
       "          2.4208e+00,  1.1291e+00,  1.0435e-01,  6.5024e-01,  1.4991e-01,\n",
       "         -6.4247e-01,  6.5398e-01, -2.7965e+00,  4.1619e-01,  1.8597e+00,\n",
       "          2.1510e-01,  8.1932e-01, -2.6283e-03,  8.9994e-01, -1.4355e+00,\n",
       "          3.4903e-01, -1.1853e+00, -4.1886e-01,  6.2018e-01, -7.5728e-01,\n",
       "          2.9207e-01, -5.5236e-02, -1.2092e-01,  1.0442e+00,  2.5155e+00,\n",
       "         -1.3820e+00,  3.1046e-01,  7.7836e-01,  2.3206e+00, -7.2625e-01,\n",
       "         -6.4145e-01, -5.2552e-01,  1.0943e+00, -2.0462e-01,  1.5614e+00,\n",
       "         -5.1006e-01, -2.7262e+00, -1.3340e+00, -7.5604e-01, -8.0209e-01,\n",
       "          1.0104e+00,  1.1085e+00, -8.9468e-01, -9.0325e-01,  3.4610e-01,\n",
       "          7.8071e-01, -6.7878e-01, -6.3907e-01, -8.3081e-01,  7.1948e-01],\n",
       "        requires_grad=True),\n",
       " 'b2': tensor([-1.8479, -1.2835, -0.8046,  1.2156, -0.5451, -0.1639,  0.1970,  1.6821,\n",
       "          0.7255, -0.6629,  0.7393,  0.0266,  1.7090,  0.1817, -0.6258,  1.2586,\n",
       "         -0.1265, -0.0734, -0.0164, -1.4680,  0.7824, -0.6331, -1.0645, -1.4530,\n",
       "          0.2599, -1.1953,  0.6448], requires_grad=True)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def back_pass(parameters, nll_loss, lr=.1):\n",
    "    # nullifying param grads\n",
    "    for p in parameters.values():\n",
    "        p.grad = None\n",
    "\n",
    "    #backprop\n",
    "    nll_loss.backward()\n",
    "\n",
    "    #params update\n",
    "    for p in parameters.values():\n",
    "        p.data += -lr * p.grad\n",
    "    \n",
    "    return parameters \n",
    "\n",
    "back_pass(parameters, nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b968681",
   "metadata": {},
   "source": [
    "<a name='3-6'></a>\n",
    "## Training in one loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02e23457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e09377f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.197283744812012\n",
      "4.446802139282227\n",
      "1.6794312000274658\n",
      "0.8483089208602905\n",
      "0.597321093082428\n",
      "0.4901702404022217\n",
      "0.42859870195388794\n",
      "0.3887881636619568\n",
      "0.3614749610424042\n",
      "0.3420078158378601\n"
     ]
    }
   ],
   "source": [
    "parameters = initiate_params(len(chars))\n",
    "\n",
    "for _ in range(100):\n",
    "    logits = forward_pass(X, parameters)\n",
    "    nll_loss = F.cross_entropy(logits, Y)\n",
    "    parameters = back_pass(parameters, nll_loss, lr=.1)\n",
    "    \n",
    "    if _ % 10 == 0:\n",
    "        print(nll_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f39c1f",
   "metadata": {},
   "source": [
    "The loss is very small b/c the initial dataset is very small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5d7120c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b54f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuilding the trainset\n",
    "ds_dict = build_dataset(block_size=block_size, words_num=-1, verbose=False)\n",
    "X = ds_dict['X']\n",
    "Y = ds_dict['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a62f3fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.005897521972656\n",
      "9.597808837890625\n",
      "6.799360275268555\n",
      "5.449086666107178\n",
      "4.684425354003906\n",
      "4.222171783447266\n",
      "3.929347276687622\n",
      "3.7318594455718994\n",
      "3.603271007537842\n",
      "3.5002830028533936\n",
      "Time elapsed: 0:00:21.521483\n"
     ]
    }
   ],
   "source": [
    "# Retraining on all of the trainset\n",
    "parameters = initiate_params(len(chars))\n",
    "\n",
    "t1 = datetime.now()\n",
    "for _ in range(100):\n",
    "    logits = forward_pass(X, parameters)\n",
    "    nll_loss = F.cross_entropy(logits, Y)\n",
    "    parameters = back_pass(parameters, nll_loss, lr=.1)\n",
    "    \n",
    "    if _ % 10 == 0:\n",
    "        print(nll_loss.item())\n",
    "t2 = datetime.now()\n",
    "\n",
    "print(f'Time elapsed: {t2-t1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc7ae4c",
   "metadata": {},
   "source": [
    "<a name='3-7'></a>\n",
    "## Model imporvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802c38fc",
   "metadata": {},
   "source": [
    "Took a long time b/c each training iteration was done on the whole dataset. Instead random minibatches could be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "10496963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([193625,  24865,  61208, 192725,  72701,  52207,  15506, 108383,  78678,\n",
       "        179714, 111859, 112858,  59691, 182537, 167681,  75104,  36633, 182665,\n",
       "        221811, 194286,  70086, 220742, 174216, 179509,   5797, 151633, 103770,\n",
       "         23439, 151858,  35166, 190512,  62448])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of 32 indices between 0 and the length of the trainset\n",
    "torch.randint(0, X.shape[0], (32,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2010e292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  8,  1],\n",
       "        [18,  9, 19],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  7],\n",
       "        [ 0, 20, 15],\n",
       "        [ 0,  4, 21],\n",
       "        [ 0,  0,  0],\n",
       "        [26,  1,  2],\n",
       "        [ 4, 15, 14],\n",
       "        [12,  1, 14],\n",
       "        [ 5, 13,  5],\n",
       "        [12,  9, 20],\n",
       "        [ 1, 14,  9],\n",
       "        [ 0, 11,  8],\n",
       "        [ 9,  3,  5],\n",
       "        [ 4,  5, 14],\n",
       "        [ 0,  0,  0],\n",
       "        [ 4,  1,  9],\n",
       "        [ 1, 14,  1],\n",
       "        [12,  9, 15],\n",
       "        [ 9, 18,  5],\n",
       "        [ 2,  1,  3],\n",
       "        [14, 20, 18],\n",
       "        [ 0,  0, 12],\n",
       "        [ 0,  0,  0],\n",
       "        [10,  1,  9],\n",
       "        [ 0,  0, 18],\n",
       "        [14,  9, 14],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [21,  1, 12],\n",
       "        [ 0,  0,  6]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[torch.randint(0, X.shape[0], (32,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2e74b004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.926416397094727\n",
      "4.401364803314209\n",
      "3.3355259895324707\n",
      "2.8897223472595215\n",
      "3.333444595336914\n",
      "2.7860195636749268\n",
      "2.5920724868774414\n",
      "2.2694382667541504\n",
      "3.1327149868011475\n",
      "2.6819007396698\n",
      "Time elapsed: 0:00:00.507156\n"
     ]
    }
   ],
   "source": [
    "# Retraining on all of the trainset\n",
    "parameters = initiate_params(len(chars))\n",
    "\n",
    "t1 = datetime.now()\n",
    "for _ in range(1000):\n",
    "    \n",
    "    #minibatch construct\n",
    "    ix = torch.randint(0, X.shape[0], (32,))\n",
    "    miniB_X = X[ix]\n",
    "    miniB_Y = Y[ix]\n",
    "    \n",
    "    #train epoch\n",
    "    logits = forward_pass(miniB_X, parameters)\n",
    "    nll_loss = F.cross_entropy(logits, miniB_Y)\n",
    "    parameters = back_pass(parameters, nll_loss, lr=.1)\n",
    "    \n",
    "    if _ % 100 == 0:\n",
    "        print(nll_loss.item())\n",
    "t2 = datetime.now()\n",
    "\n",
    "print(f'Time elapsed: {t2-t1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0221755b",
   "metadata": {},
   "source": [
    "About the same loss minimisation progression, but at a fraction of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dc5f1267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6437, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating on the whole dataset\n",
    "logits = forward_pass(X, parameters)\n",
    "nll_loss = F.cross_entropy(logits, Y)\n",
    "nll_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecea70a",
   "metadata": {},
   "source": [
    "<a name='3-6-1'></a>\n",
    "### Train, eval, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c5b138e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "35b0a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percent = 0.8\n",
    "train_start_ix, train_end_ix = 0, int(train_percent * (len(words)))\n",
    "eval_start_ix, eval_end_ix = train_end_ix+1, train_end_ix + int((len(words) - train_end_ix)/2)\n",
    "test_start_ix, test_end_ix = eval_end_ix+1, len(words)-1\n",
    "# eval_percent, test_percent = 1-train_percent/2,  1-train_percent/2; \n",
    "\n",
    "random.shuffle(words)\n",
    "train_ds_dict = build_dataset(words=words[train_start_ix:train_end_ix], verbose=False)\n",
    "train_X = train_ds_dict['X']; train_Y = train_ds_dict['Y']\n",
    "\n",
    "eval_ds_dict = build_dataset(words=words[eval_start_ix:eval_end_ix], verbose=False)\n",
    "eval_X = eval_ds_dict['X']; eval_Y = eval_ds_dict['Y']\n",
    "\n",
    "test_ds_dict = build_dataset(words=words[test_start_ix:test_end_ix], verbose=False)\n",
    "test_X = test_ds_dict['X']; test_Y = test_ds_dict['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "87c91d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_X, train_Y, parameters, lr=0.1, batch_size=32,\n",
    "          epochs=15000, verbose=True):\n",
    "    for _ in range(epochs):\n",
    "        #minibatch construct\n",
    "        ix = torch.randint(0, train_X.shape[0], (batch_size,))\n",
    "        miniB_X = train_X[ix]\n",
    "        miniB_Y = train_Y[ix]\n",
    "\n",
    "        #train epoch\n",
    "        logits = forward_pass(miniB_X, parameters)\n",
    "        nll_loss = F.cross_entropy(logits, miniB_Y)\n",
    "        parameters = back_pass(parameters, nll_loss, lr=lr)\n",
    "\n",
    "        if (_ % int(epochs/5) == 0) and verbose: \n",
    "            print(nll_loss.item())\n",
    "    return parameters\n",
    "\n",
    "def eval_model(parameters, train_X, train_Y, eval_X, eval_Y, test_X, test_Y):\n",
    "    \n",
    "    # evaluating on the whole training dataset\n",
    "    logits = forward_pass(train_X, parameters)\n",
    "    nll_loss_train = F.cross_entropy(logits, train_Y)\n",
    "    \n",
    "    # evaluating on the eval dataset\n",
    "    logits = forward_pass(eval_X, parameters)\n",
    "    nll_loss_eval = F.cross_entropy(logits, eval_Y)\n",
    "    \n",
    "    # evaluating on the test dataset\n",
    "    logits = forward_pass(test_X, parameters)\n",
    "    nll_loss_test = F.cross_entropy(logits, test_Y)\n",
    "    \n",
    "    return {'train': nll_loss_train.item(), 'eval': nll_loss_eval.item(), 'test': nll_loss_test.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d53d7b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.652084350585938\n",
      "2.4685938358306885\n",
      "2.4793920516967773\n",
      "2.3250765800476074\n",
      "2.3858280181884766\n",
      "Time elapsed: 0:00:12.985690\n"
     ]
    }
   ],
   "source": [
    "# Retraining on all of the trainset\n",
    "parameters = initiate_params(len(chars), hidden_layer_size=100)\n",
    "parameters = train(train_X, train_Y, parameters, epochs=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "97cc5135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 2.37899112701416,\n",
       " 'eval': 2.3843002319335938,\n",
       " 'test': 2.3770201206207275}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(parameters, train_X, train_Y, eval_X, eval_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c574e4c",
   "metadata": {},
   "source": [
    "<a name='3-6-2'></a>\n",
    "### Increasing the model size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07443f84",
   "metadata": {},
   "source": [
    "Score on train and eval sets are about the same, we are underfitting, we can improve performace by increasing the model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "54a80b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.692665100097656\n",
      "2.5410609245300293\n",
      "3.414820909500122\n",
      "2.6682658195495605\n",
      "2.7370643615722656\n"
     ]
    }
   ],
   "source": [
    "# Retraining on all of the trainset with increased model size\n",
    "parameters = initiate_params(len(chars), hidden_layer_size=300)\n",
    "parameters = train(train_X, train_Y, parameters, epochs=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e707a69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 2.5114986896514893,\n",
       " 'eval': 2.5211033821105957,\n",
       " 'test': 2.4954404830932617}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(parameters, train_X, train_Y, eval_X, eval_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9681c2",
   "metadata": {},
   "source": [
    "We can increase the training duration, decrease learning rate and increase the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6ce38739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.59946060180664\n",
      "2.408470630645752\n",
      "2.454009771347046\n",
      "2.3968396186828613\n",
      "2.2818920612335205\n"
     ]
    }
   ],
   "source": [
    "# Retraining on all of the trainset with increased batch size and training duration\n",
    "parameters = initiate_params(len(chars), hidden_layer_size=300)\n",
    "parameters = train(train_X, train_Y, parameters, epochs=300000, batch_size=64, lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "472bf1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 2.3119144439697266,\n",
       " 'eval': 2.315922975540161,\n",
       " 'test': 2.314150094985962}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(parameters, train_X, train_Y, eval_X, eval_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6843f7",
   "metadata": {},
   "source": [
    "Increase the embedding size from 2 to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "27be8d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.56483268737793\n",
      "2.4127919673919678\n",
      "2.3729515075683594\n",
      "2.1194214820861816\n",
      "2.2924582958221436\n"
     ]
    }
   ],
   "source": [
    "parameters = initiate_params(len(chars), hidden_layer_size=300, embedding_size=10)\n",
    "parameters = train(train_X, train_Y, parameters, epochs=500000, batch_size=64, lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e48da5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 2.142258405685425, 'eval': 2.1806640625, 'test': 2.1684632301330566}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(parameters, train_X, train_Y, eval_X, eval_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96d2596",
   "metadata": {},
   "source": [
    "<a name='3-6-3'></a>\n",
    "### LR decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a01ed6",
   "metadata": {},
   "source": [
    "Decay learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c9cc8f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== 300000 0.1 ==============================\n",
      "30.4615421295166\n",
      "2.0137808322906494\n",
      "2.174171209335327\n",
      "2.0147619247436523\n",
      "1.9467006921768188\n",
      "============================== 150000 0.04 ==============================\n",
      "2.207733392715454\n",
      "2.2263317108154297\n",
      "1.970402479171753\n",
      "2.0515661239624023\n",
      "1.9990328550338745\n",
      "============================== 75000 0.02 ==============================\n",
      "2.2195701599121094\n",
      "1.8307344913482666\n",
      "2.060786724090576\n",
      "2.1697745323181152\n",
      "2.1351871490478516\n",
      "============================== 50000 0.01 ==============================\n",
      "1.9666452407836914\n",
      "1.9726721048355103\n",
      "2.273517370223999\n",
      "1.9514293670654297\n",
      "2.115074872970581\n"
     ]
    }
   ],
   "source": [
    "# Retraining on all of the trainset with increased batch size and training duration\n",
    " \n",
    "for epochs, lr in zip([300000, 150000, 75000, 50000], [0.1, 0.04, 0.02, 0.01]):\n",
    "    print('='*30, epochs, lr, '='*30)\n",
    "    parameters = train(train_X, train_Y, parameters, epochs=epochs, batch_size=64, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "817d91a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 2.0251619815826416,\n",
       " 'eval': 2.1231932640075684,\n",
       " 'test': 2.1158018112182617}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(parameters, train_X, train_Y, eval_X, eval_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a85cd3",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ed7d6cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  4],\n",
       "        [ 0,  4,  5],\n",
       "        ...,\n",
       "        [ 9, 13, 15],\n",
       "        [13, 15, 14],\n",
       "        [15, 14,  5]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "0c7b1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = torch.tensor([0]*BLOCK_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "8c9eff3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22810, 27])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass(test_X, parameters).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "696fc961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yofo',\n",
       " 'casse',\n",
       " 'jabrisci',\n",
       " 'raeton',\n",
       " 'shanstyn',\n",
       " 'huna',\n",
       " 'zinahkifa',\n",
       " 'kaide',\n",
       " 'silvuke',\n",
       " 'aalairah',\n",
       " 'ayphorna',\n",
       " 'sree',\n",
       " 'diy',\n",
       " 'mani',\n",
       " 'keion']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_name_nn(num_names, parameters):\n",
    "    '''\n",
    "    Here we start with first row because it contains first letters of names, \n",
    "    sample a letter (or collumn), \n",
    "    this letter gives us the number or a row to sample next from.\n",
    "    This is repeated until the end token is sampled.\n",
    "    '''\n",
    "    \n",
    "    out = []\n",
    "    for cnt in range(num_names):\n",
    "        this_name = []\n",
    "        context = [0]*BLOCK_SIZE\n",
    "        for _ in range(50):\n",
    "            \n",
    "            #forward pass\n",
    "            logits = forward_pass(torch.tensor(context), parameters)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            \n",
    "            #sampling\n",
    "            ix = torch.multinomial(probs, num_samples=1, replacement=True).item()\n",
    "            context = context[1:] + [ix]\n",
    "            this_name.append(itos[ix])\n",
    "            \n",
    "            if ix == 0:\n",
    "                 break\n",
    "        out.append(''.join(this_name)[:-1])\n",
    "    return out\n",
    "\n",
    "\n",
    "generate_name_nn(15, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f203a2",
   "metadata": {},
   "source": [
    "At this stage we've achieved better model score and more adequate names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practical_rl_course",
   "language": "python",
   "name": "practical_rl_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
